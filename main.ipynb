{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetching data from [cryptocompare.com](https://www.cryptocompare.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class CryptoApi:\n",
    "    def __init__(self) -> None:\n",
    "        self.mother_endpoint = \"https://min-api.cryptocompare.com/data\"\n",
    "\n",
    "        with open('token.txt', 'r') as f:\n",
    "            self.TOKEN = f.readline()\n",
    "\n",
    "        self.HEADER = {'Authorization': self.TOKEN,\n",
    "                       \"Content-Type\": 'application/json'}\n",
    "\n",
    "\n",
    "    def get_data(self, crypto:str, currency:str, period:str, period_count:int, allData=0):\n",
    "        '''Returns crypto summary for a given period in specified currency.\n",
    "\n",
    "        Args:\n",
    "            crypto: str\n",
    "                BTC/ETH/DOGE etc.\n",
    "            currency: str\n",
    "                USD/EUR/UAH etc.\n",
    "            period: str \n",
    "                day/hour/minute.\n",
    "            period_count: int\n",
    "                last n of a period (n days)\n",
    "                n = 1 returns revious day/hour/minute + current\n",
    "            allData: int\n",
    "                bool doen't work\n",
    "                1 - get all records;\n",
    "                0 - get specified amount of period_count.\n",
    "        Returns:\n",
    "            dict: json containing request's response.\n",
    "        '''        \n",
    "\n",
    "        endpoint = f'{self.mother_endpoint}/v2/histo{period}?fsym={crypto}&tsym={currency}&limit={period_count}'\n",
    "        response = requests.get(endpoint, params={'allData':allData}, headers=self.HEADER)\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def execute_custom_getrequest(self, endpoint:str):\n",
    "        return requests.get(endpoint, headers=self.HEADER)\n",
    "    \n",
    "data = CryptoApi()\n",
    "#data.get_data('btc','usd','day',29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "date_range = pd.date_range(start='2023-04-11', end='2023-04-13', freq='d')\n",
    "\n",
    "queries = [f\"from:elonmusk since:{d1.strftime('%Y-%m-%d')} until:{d2.strftime('%Y-%m-%d')}\"\n",
    "           for d1, d2 in zip(date_range, date_range[1:])]\n",
    "\n",
    "\n",
    "def parallel_download_tweets():\n",
    "    def sequent_download_tweets(query):\n",
    "        tweets = []\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "\n",
    "    tweets_list = []\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(sequent_download_tweets, query) for query in queries]\n",
    "            \n",
    "        # Append results to the tweets list\n",
    "        for future in as_completed(futures):\n",
    "            tweets_list += future.result()\n",
    "            \n",
    "    return tweets_list\n",
    "\n",
    "\n",
    "#tweets_df = pd.DataFrame(parallel_download_tweets())\n",
    "#tweets_df.to_csv('elon_twt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "raw_data = data.get_data('btc','usd','day',30)\n",
    "\n",
    "df = pd.DataFrame(raw_data['Data']['Data'])\n",
    "df['time'] = df['time'].apply(lambda x: datetime.fromtimestamp(x).date())\n",
    "\n",
    "raw_btc = data.get_data('btc','usd','day', 2000) #10 years bitcoin\n",
    "\n",
    "\n",
    "btc_df = pd.DataFrame(raw_btc['Data']['Data'])\n",
    "btc_df['time'] = btc_df['time'].apply(lambda x: datetime.fromtimestamp(x).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\nfiltered_df = btc_df[btc_df['time']>=datetime.strptime('2022-05-15','%Y-%m-%d').date()].copy()\\nfiltered_df.index = filtered_df['time']\\n\\n\\nplt.figure(figsize=(12,8))\\nplt.plot(filtered_df['close'])\\nplt.plot(filtered_df['close'].rolling(28).mean())\""
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "filtered_df = btc_df[btc_df['time']>=datetime.strptime('2022-05-15','%Y-%m-%d').date()].copy()\n",
    "filtered_df.index = filtered_df['time']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(filtered_df['close'])\n",
    "plt.plot(filtered_df['close'].rolling(28).mean())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plotMovingAverage(series, window, plot_intervals=False, scale=1.96, plot_anomalies=False):\n",
    "    \"\"\"\n",
    "        series - dataframe with timeseries\n",
    "        window - rolling window size \n",
    "        plot_intervals - show confidence intervals\n",
    "        plot_anomalies - show anomalies \n",
    "    \"\"\"\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plt.title(\"Moving average\\n window size = {}\".format(window))\n",
    "    plt.plot(rolling_mean, \"g\", label=\"Rolling mean trend\")\n",
    "\n",
    "    # Plot confidence intervals for smoothed values\n",
    "    if plot_intervals:\n",
    "        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n",
    "        deviation = np.std(series[window:] - rolling_mean[window:])\n",
    "        lower_bond = rolling_mean - (mae + scale * deviation)\n",
    "        upper_bond = rolling_mean + (mae + scale * deviation)\n",
    "        plt.plot(upper_bond, \"r--\", label=\"Upper Bond / Lower Bond\")\n",
    "        plt.plot(lower_bond, \"r--\")\n",
    "        \n",
    "        # Having the intervals, find abnormal values\n",
    "        if plot_anomalies:\n",
    "            anomalies = pd.DataFrame(index=series.index, columns=series.columns)\n",
    "            anomalies[series < lower_bond] = series[series < lower_bond]\n",
    "            anomalies[series > upper_bond] = series[series > upper_bond]\n",
    "            plt.plot(anomalies, \"ro\", markersize=10, label='Anomalies')\n",
    "        \n",
    "    plt.plot(series[window:], label=\"Actual values\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "#plotMovingAverage(filtered_df[['close']], 30, plot_intervals=True, plot_anomalies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(series, alpha):\n",
    "    \"\"\"\n",
    "        series - dataset with timestamps\n",
    "        alpha - float [0.0, 1.0], smoothing parameter\n",
    "    \"\"\"\n",
    "    result = [series[0]] # first value is same as series\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result\n",
    "    \n",
    "def plotExponentialSmoothing(series, alphas):\n",
    "    \"\"\"\n",
    "        Plots exponential smoothing with different alphas\n",
    "        \n",
    "        series - dataset with timestamps\n",
    "        alphas - list of floats, smoothing parameters\n",
    "        \n",
    "    \"\"\"\n",
    "    with plt.style.context('seaborn-white'):    \n",
    "        plt.figure(figsize=(15, 7))\n",
    "        for alpha in alphas:\n",
    "            plt.plot(exponential_smoothing(series, alpha), label=f\"Alpha {alpha}\")\n",
    "            \n",
    "        plt.plot(series.values, \"c\", label = \"Actual\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.axis('tight')\n",
    "        plt.title(\"Exponential Smoothing\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "#plotExponentialSmoothing(currency.GEMS_GEMS_SPENT, [0.3, 0.05])\n",
    "#plotExponentialSmoothing(filtered_df['close'], [0.05, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_exponential_smoothing(series, alpha, beta):\n",
    "    \"\"\"\n",
    "        series - dataset with timeseries\n",
    "        alpha - float [0.0, 1.0], smoothing parameter for level\n",
    "        beta - float [0.0, 1.0], smoothing parameter for trend\n",
    "    \"\"\"\n",
    "    # first value is same as series\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)+1):\n",
    "        if n == 1:\n",
    "            level, trend = series[0], series[1] - series[0]\n",
    "        if n >= len(series): # forecasting\n",
    "            value = result[-1]\n",
    "        else:\n",
    "            value = series[n]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "    return result\n",
    "\n",
    "def plotDoubleExponentialSmoothing(series, alphas, betas):\n",
    "    \"\"\"\n",
    "        Plots double exponential smoothing with different alphas and betas\n",
    "        \n",
    "        series - dataset with timestamps\n",
    "        alphas - list of floats, smoothing parameters for level\n",
    "        betas - list of floats, smoothing parameters for trend\n",
    "    \"\"\"\n",
    "    \n",
    "    with plt.style.context('seaborn-white'):    \n",
    "        plt.figure(figsize=(20, 8))\n",
    "        for alpha in alphas:\n",
    "            for beta in betas:\n",
    "                plt.plot(double_exponential_smoothing(series, alpha, beta), label=\"Alpha {}, beta {}\".format(alpha, beta))\n",
    "        plt.plot(series.values, label = \"Actual\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.axis('tight')\n",
    "        plt.title(\"Double Exponential Smoothing\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "#plotDoubleExponentialSmoothing(filtered_df['close'], alphas=[0.9, 0.02], betas=[0.9, 0.02])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets_df = pd.read_csv('elon_tweets.csv', index_col=0)\n",
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'])\n",
    "\n",
    "def select_notna_cols(df: pd.DataFrame, threshold: float):\n",
    "    \"\"\"\n",
    "    Selects columns with at least the specified proportion of non-null values.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame to select columns from.\n",
    "        threshold (float): The minimum proportion of non-null values a column must have to be selected.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: The names of the selected columns.\n",
    "    \"\"\"\n",
    "\n",
    "    proportions = df.notnull().mean()\n",
    "    selected_cols = proportions[proportions >= threshold].index.tolist()\n",
    "    \n",
    "    return selected_cols\n",
    "\n",
    "notna_cols = select_notna_cols(tweets_df, threshold=0.4)\n",
    "mod_tweets_df = tweets_df[notna_cols].copy()\n",
    "\n",
    "mod_tweets_df = (mod_tweets_df[mod_tweets_df['lang']=='en']\n",
    "                 .drop(['id','url','source','sourceUrl'], axis=1)\n",
    "                 .reset_index(drop=True)\n",
    "                 .copy())\n",
    "\n",
    "\n",
    "mod_tweets_df = mod_tweets_df.drop(['lang','inReplyToTweetId','conversationId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO: \\n0) find a way to deal with multiple tweets for a day\\n1) merge 2 datasets into \\n2) imput missing data, maybe try interpolation or expectation maximization\\n    2.1) compare with mean, median imput methods\\n3) ivestigate relationship within data, maybe correlation matrix etc\\n'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO: \n",
    "0) find a way to deal with multiple tweets for a day\n",
    "1) merge 2 datasets into \n",
    "2) imput missing data, maybe try interpolation or expectation maximization\n",
    "    2.1) compare with mean, median imput methods\n",
    "3) ivestigate relationship within data, maybe correlation matrix etc\n",
    "'''\n",
    "\n",
    "#data.get_data('btc', 'usd', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@dogeofficialceo Passing butter\\nhttps://t.co/BQodkxl2BZ',\n",
       "       '@dogeofficialceo Passing butter\\nm.youtube.com/watch?v=3ht-Zy…'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_tweets_df[mod_tweets_df['rawContent']!=mod_tweets_df['renderedContent']][['rawContent','renderedContent']].values[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "mod_tweets_df['sourceLabel_encoded'] = encoder.fit_transform(mod_tweets_df['sourceLabel'].values.reshape(-1, 1))\n",
    "mod_tweets_df['isReplied']   = [0 if type(tweet)==float else 1 for tweet in mod_tweets_df['inReplyToUser']]\n",
    "mod_tweets_df['isMentioned'] = [0 if type(tweet)==float else 1 for tweet in mod_tweets_df['mentionedUsers']]\n",
    "\n",
    "mod_tweets_df = mod_tweets_df.drop(['sourceLabel','inReplyToUser','mentionedUsers'], axis=1)\n",
    "\n",
    "\n",
    "def extract_dict(line: str, prepare_to_df: False):\n",
    "    \"\"\"Extracts data from a dict represented as string and makes it a dict.\n",
    "\n",
    "    Args:\n",
    "        line (str): row of a Series/DataFrame to be preprocessed.\n",
    "        prepare_to_df (bool): prepares extracted dict to be wrapped into DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dict: extracted dict from string.\n",
    "    \"\"\"    \n",
    "    import re\n",
    "\n",
    "    extracted_content = dict(re.findall(r\"'(\\w+)': '?({.*}|datetime.datetime\\(.*\\)|[\\w\\d/:\\. ]*)'?\", line))\n",
    "    \n",
    "    # Wraps dict values into lists to be easily represented as a DataFrame row.\n",
    "    if prepare_to_df:\n",
    "        for key,value in extracted_content.items():\n",
    "            if value == '':\n",
    "                extracted_content[key] = [None]\n",
    "            else:\n",
    "                extracted_content[key] = value\n",
    "        \n",
    "    return extracted_content\n",
    "\n",
    "\n",
    "new_df = mod_tweets_df.copy()\n",
    "extracted_df = (pd.DataFrame([*mod_tweets_df['user']\n",
    "                              .apply(lambda x: extract_dict(x, True))])\n",
    "                .drop(['username','id','displayname','verified','created','location',\n",
    "                       'protected','link','profileImageUrl','profileBannerUrl','label'], axis=1))\n",
    "\n",
    "new_df = pd.concat([new_df, extracted_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rawContent</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>user</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>sourceLabel_encoded</th>\n",
       "      <th>isReplied</th>\n",
       "      <th>isMentioned</th>\n",
       "      <th>rawDescription</th>\n",
       "      <th>renderedDescription</th>\n",
       "      <th>descriptionLinks</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>favouritesCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-04 18:31:57+00:00</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>1198</td>\n",
       "      <td>658</td>\n",
       "      <td>6359</td>\n",
       "      <td>326</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134458744</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119975</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-01 10:29:04+00:00</td>\n",
       "      <td>I made the volume on the Model S http://t.co/w...</td>\n",
       "      <td>I made the volume on the Model S ow.ly/i/mtD7 ...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134458941</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119975</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-01 09:55:11+00:00</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>198</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134458941</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119975</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-03 08:22:07+00:00</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134458911</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119975</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-03 08:20:28+00:00</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134458911</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119975</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18311</th>\n",
       "      <td>2023-04-09 01:03:23+00:00</td>\n",
       "      <td>@DimaZeniuk @SpaceX @SirineAti @captainarve @a...</td>\n",
       "      <td>@DimaZeniuk @SpaceX @SirineAti @captainarve @a...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>202</td>\n",
       "      <td>249</td>\n",
       "      <td>3511</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134460421</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119978</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18312</th>\n",
       "      <td>2023-04-09 01:01:50+00:00</td>\n",
       "      <td>@DimaZeniuk @SpaceX @SirineAti @captainarve @a...</td>\n",
       "      <td>@DimaZeniuk @SpaceX @SirineAti @captainarve @a...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>1299</td>\n",
       "      <td>1216</td>\n",
       "      <td>20873</td>\n",
       "      <td>147</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134460421</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119978</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18313</th>\n",
       "      <td>2023-04-09 00:40:39+00:00</td>\n",
       "      <td>@teslaownersSV Got to break a few eggs to make...</td>\n",
       "      <td>@teslaownersSV Got to break a few eggs to make...</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>4826</td>\n",
       "      <td>4900</td>\n",
       "      <td>113346</td>\n",
       "      <td>391</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134460421</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119978</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18314</th>\n",
       "      <td>2023-04-09 00:33:35+00:00</td>\n",
       "      <td>@Jason @DeanPreston @GrowSF Good question</td>\n",
       "      <td>@Jason @DeanPreston @GrowSF Good question</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>166</td>\n",
       "      <td>179</td>\n",
       "      <td>2663</td>\n",
       "      <td>14</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134460421</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119978</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18315</th>\n",
       "      <td>2023-04-09 00:32:27+00:00</td>\n",
       "      <td>Friendship takes work, enmity is effortless</td>\n",
       "      <td>Friendship takes work, enmity is effortless</td>\n",
       "      <td>{'username': 'elonmusk', 'id': 44196397, 'disp...</td>\n",
       "      <td>8821</td>\n",
       "      <td>20876</td>\n",
       "      <td>145759</td>\n",
       "      <td>1571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>None</td>\n",
       "      <td>134460421</td>\n",
       "      <td>193</td>\n",
       "      <td>24445</td>\n",
       "      <td>20702</td>\n",
       "      <td>119978</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18316 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date  \\\n",
       "0     2010-06-04 18:31:57+00:00   \n",
       "1     2011-12-01 10:29:04+00:00   \n",
       "2     2011-12-01 09:55:11+00:00   \n",
       "3     2011-12-03 08:22:07+00:00   \n",
       "4     2011-12-03 08:20:28+00:00   \n",
       "...                         ...   \n",
       "18311 2023-04-09 01:03:23+00:00   \n",
       "18312 2023-04-09 01:01:50+00:00   \n",
       "18313 2023-04-09 00:40:39+00:00   \n",
       "18314 2023-04-09 00:33:35+00:00   \n",
       "18315 2023-04-09 00:32:27+00:00   \n",
       "\n",
       "                                              rawContent  \\\n",
       "0      Please ignore prior tweets, as that was someon...   \n",
       "1      I made the volume on the Model S http://t.co/w...   \n",
       "2      Went to Iceland on Sat to ride bumper cars on ...   \n",
       "3                      That was a total non sequitur btw   \n",
       "4      Great Voltaire quote, arguably better than Twa...   \n",
       "...                                                  ...   \n",
       "18311  @DimaZeniuk @SpaceX @SirineAti @captainarve @a...   \n",
       "18312  @DimaZeniuk @SpaceX @SirineAti @captainarve @a...   \n",
       "18313  @teslaownersSV Got to break a few eggs to make...   \n",
       "18314          @Jason @DeanPreston @GrowSF Good question   \n",
       "18315        Friendship takes work, enmity is effortless   \n",
       "\n",
       "                                         renderedContent  \\\n",
       "0      Please ignore prior tweets, as that was someon...   \n",
       "1      I made the volume on the Model S ow.ly/i/mtD7 ...   \n",
       "2      Went to Iceland on Sat to ride bumper cars on ...   \n",
       "3                      That was a total non sequitur btw   \n",
       "4      Great Voltaire quote, arguably better than Twa...   \n",
       "...                                                  ...   \n",
       "18311  @DimaZeniuk @SpaceX @SirineAti @captainarve @a...   \n",
       "18312  @DimaZeniuk @SpaceX @SirineAti @captainarve @a...   \n",
       "18313  @teslaownersSV Got to break a few eggs to make...   \n",
       "18314          @Jason @DeanPreston @GrowSF Good question   \n",
       "18315        Friendship takes work, enmity is effortless   \n",
       "\n",
       "                                                    user  replyCount  \\\n",
       "0      {'username': 'elonmusk', 'id': 44196397, 'disp...        1198   \n",
       "1      {'username': 'elonmusk', 'id': 44196397, 'disp...          28   \n",
       "2      {'username': 'elonmusk', 'id': 44196397, 'disp...          42   \n",
       "3      {'username': 'elonmusk', 'id': 44196397, 'disp...          42   \n",
       "4      {'username': 'elonmusk', 'id': 44196397, 'disp...          35   \n",
       "...                                                  ...         ...   \n",
       "18311  {'username': 'elonmusk', 'id': 44196397, 'disp...         202   \n",
       "18312  {'username': 'elonmusk', 'id': 44196397, 'disp...        1299   \n",
       "18313  {'username': 'elonmusk', 'id': 44196397, 'disp...        4826   \n",
       "18314  {'username': 'elonmusk', 'id': 44196397, 'disp...         166   \n",
       "18315  {'username': 'elonmusk', 'id': 44196397, 'disp...        8821   \n",
       "\n",
       "       retweetCount  likeCount  quoteCount  sourceLabel_encoded  isReplied  \\\n",
       "0               658       6359         326                  5.0          0   \n",
       "1                12         80           8                  5.0          0   \n",
       "2                27        198           7                  5.0          0   \n",
       "3                17        144           8                  7.0          0   \n",
       "4                34         86           5                  7.0          0   \n",
       "...             ...        ...         ...                  ...        ...   \n",
       "18311           249       3511          30                  7.0          1   \n",
       "18312          1216      20873         147                  7.0          1   \n",
       "18313          4900     113346         391                  7.0          1   \n",
       "18314           179       2663          14                  7.0          1   \n",
       "18315         20876     145759        1571                  7.0          0   \n",
       "\n",
       "       isMentioned rawDescription renderedDescription descriptionLinks  \\\n",
       "0                0         [None]              [None]             None   \n",
       "1                0         [None]              [None]             None   \n",
       "2                0         [None]              [None]             None   \n",
       "3                0         [None]              [None]             None   \n",
       "4                0         [None]              [None]             None   \n",
       "...            ...            ...                 ...              ...   \n",
       "18311            1         [None]              [None]             None   \n",
       "18312            1         [None]              [None]             None   \n",
       "18313            1         [None]              [None]             None   \n",
       "18314            1         [None]              [None]             None   \n",
       "18315            0         [None]              [None]             None   \n",
       "\n",
       "      followersCount friendsCount statusesCount favouritesCount listedCount  \\\n",
       "0          134458744          193         24445           20702      119975   \n",
       "1          134458941          193         24445           20702      119975   \n",
       "2          134458941          193         24445           20702      119975   \n",
       "3          134458911          193         24445           20702      119975   \n",
       "4          134458911          193         24445           20702      119975   \n",
       "...              ...          ...           ...             ...         ...   \n",
       "18311      134460421          193         24445           20702      119978   \n",
       "18312      134460421          193         24445           20702      119978   \n",
       "18313      134460421          193         24445           20702      119978   \n",
       "18314      134460421          193         24445           20702      119978   \n",
       "18315      134460421          193         24445           20702      119978   \n",
       "\n",
       "      mediaCount  \n",
       "0           1492  \n",
       "1           1492  \n",
       "2           1492  \n",
       "3           1492  \n",
       "4           1492  \n",
       "...          ...  \n",
       "18311       1492  \n",
       "18312       1492  \n",
       "18313       1492  \n",
       "18314       1492  \n",
       "18315       1492  \n",
       "\n",
       "[18316 rows x 20 columns]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-06-02 20:12:29+00:00\n"
     ]
    }
   ],
   "source": [
    "def str_to_datetime(input_str):\n",
    "    from datetime import datetime, timezone\n",
    "    import re\n",
    "    # use regular expressions to extract the date and time components\n",
    "    match = re.search(r'(\\d{4}),\\s(\\d{1,2}),\\s(\\d{1,2}),\\s(\\d{1,2}),\\s(\\d{1,2}),\\s(\\d{1,2})', input_str)\n",
    "    if match:\n",
    "        year, month, day, hour, minute, second = map(int, match.groups())\n",
    "\n",
    "    # create a timezone object\n",
    "    tz = timezone.utc\n",
    "\n",
    "    # create a datetime object using the extracted components and timezone\n",
    "    dt = datetime(year, month, day, hour, minute, second, tzinfo=tz)\n",
    "\n",
    "    # print the resulting datetime object\n",
    "    print(dt)\n",
    "    \n",
    "str_to_datetime(input_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
