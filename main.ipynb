{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetching crypto and tweets data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class CryptoApi:\n",
    "    def __init__(self) -> None:\n",
    "        self.mother_endpoint = \"https://min-api.cryptocompare.com/data\"\n",
    "\n",
    "        with open('token.txt', 'r') as f:\n",
    "            self.TOKEN = f.readline()\n",
    "\n",
    "        self.HEADER = {'Authorization': self.TOKEN,\n",
    "                       \"Content-Type\": 'application/json'}\n",
    "\n",
    "\n",
    "    def get_data(self, crypto:str, currency:str, period:str, period_count:int, allData=0):\n",
    "        '''Returns crypto summary for a given period in specified currency.\n",
    "\n",
    "        Args:\n",
    "            crypto: str\n",
    "                BTC/ETH/DOGE etc.\n",
    "            currency: str\n",
    "                USD/EUR/UAH etc.\n",
    "            period: str \n",
    "                day/hour/minute.\n",
    "            period_count: int\n",
    "                last n of a period (n days)\n",
    "                n = 1 returns revious day/hour/minute + current\n",
    "            allData: int\n",
    "                bool doen't work\n",
    "                1 - get all records;\n",
    "                0 - get specified amount of period_count.\n",
    "        Returns:\n",
    "            dict: json containing request's response.\n",
    "        '''        \n",
    "\n",
    "        endpoint = f'{self.mother_endpoint}/v2/histo{period}?fsym={crypto}&tsym={currency}&limit={period_count}'\n",
    "        response = requests.get(endpoint, params={'allData':allData}, headers=self.HEADER)\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def execute_custom_getrequest(self, endpoint:str):\n",
    "        return requests.get(endpoint, headers=self.HEADER)\n",
    "    \n",
    "data = CryptoApi()\n",
    "#data.get_data('btc','usd','day',29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "date_range = pd.date_range(start='2023-04-11', end='2023-04-13', freq='d')\n",
    "\n",
    "queries = [f\"from:elonmusk since:{d1.strftime('%Y-%m-%d')} until:{d2.strftime('%Y-%m-%d')}\"\n",
    "           for d1, d2 in zip(date_range, date_range[1:])]\n",
    "\n",
    "\n",
    "def parallel_download_tweets():\n",
    "    def sequent_download_tweets(query):\n",
    "        tweets = []\n",
    "        for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "\n",
    "    tweets_list = []\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(sequent_download_tweets, query) for query in queries]\n",
    "            \n",
    "        # Append results to the tweets list\n",
    "        for future in as_completed(futures):\n",
    "            tweets_list += future.result()\n",
    "            \n",
    "    return tweets_list\n",
    "\n",
    "\n",
    "#tweets_df = pd.DataFrame(parallel_download_tweets())\n",
    "#tweets_df.to_csv('elon_twt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "raw_data = data.get_data('btc','usd','day',30)\n",
    "\n",
    "df = pd.DataFrame(raw_data['Data']['Data'])\n",
    "df['time'] = df['time'].apply(lambda x: datetime.fromtimestamp(x).date())\n",
    "\n",
    "raw_btc = data.get_data('btc','usd','day', 2000) #10 years bitcoin\n",
    "\n",
    "\n",
    "btc_df = pd.DataFrame(raw_btc['Data']['Data'])\n",
    "btc_df['time'] = btc_df['time'].apply(lambda x: datetime.fromtimestamp(x).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\n\\nfiltered_df = btc_df[btc_df['time']>=datetime.strptime('2022-05-15','%Y-%m-%d').date()].copy()\\nfiltered_df.index = filtered_df['time']\\n\\n\\nplt.figure(figsize=(12,8))\\nplt.plot(filtered_df['close'])\\nplt.plot(filtered_df['close'].rolling(28).mean())\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "\n",
    "filtered_df = btc_df[btc_df['time']>=datetime.strptime('2022-05-15','%Y-%m-%d').date()].copy()\n",
    "filtered_df.index = filtered_df['time']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(filtered_df['close'])\n",
    "plt.plot(filtered_df['close'].rolling(28).mean())'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving into sparse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "TODO: GENERAL DATA TASKS:\n",
    "0) find a way to deal with multiple tweets for a day\n",
    "1) merge 2 datasets into \n",
    "2) imput missing data, maybe try interpolation or expectation maximization\n",
    "    2.1) compare with mean, median imput methods\n",
    "3) ivestigate relationship within data, maybe correlation matrix etc\n",
    "'''\n",
    "\n",
    "tweets_df = pd.read_csv('elon_tweets.csv', index_col=0)\n",
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'])\n",
    "\n",
    "sparse_cols = tweets_df.columns[tweets_df.notnull().mean() < 1.0].values.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21775 entries, 0 to 21774\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   links             1425 non-null   object \n",
      " 1   media             1370 non-null   object \n",
      " 2   retweetedTweet    0 non-null      float64\n",
      " 3   quotedTweet       609 non-null    object \n",
      " 4   inReplyToTweetId  16915 non-null  float64\n",
      " 5   inReplyToUser     16915 non-null  object \n",
      " 6   mentionedUsers    16386 non-null  object \n",
      " 7   coordinates       0 non-null      float64\n",
      " 8   place             0 non-null      float64\n",
      " 9   hashtags          50 non-null     object \n",
      " 10  cashtags          1 non-null      object \n",
      " 11  card              853 non-null    object \n",
      " 12  viewCount         2934 non-null   float64\n",
      " 13  vibe              18 non-null     object \n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df[sparse_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment this part after dealing with sus columns\n",
    "\n",
    "'''mod_tweets_df = tweets_df[notna_cols].copy()\n",
    "\n",
    "mod_tweets_df = (mod_tweets_df[mod_tweets_df['lang']=='en']\n",
    "                 .drop(['id','url','source','sourceUrl'], axis=1)                 \n",
    "                 .reset_index(drop=True)\n",
    "                 .copy())\n",
    "\n",
    "\n",
    "#mod_tweets_df = mod_tweets_df.drop(['lang','inReplyToTweetId','conversationId'], axis=1)\n",
    "mod_tweets_df = mod_tweets_df.drop(['lang'], axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(len(mod_tweets_df))\n",
    "print(len(mod_tweets_df['conversationId'].unique()))\n",
    "print(len(mod_tweets_df['inReplyToTweetId'].unique()))\n",
    "print(mod_tweets_df['isReplied'].sum())\n",
    "print(mod_tweets_df['isReplied'].where(mod_tweets_df['isReplied'] == 0).dropna().shape[0])'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "mod_tweets_df['sourceLabel_encoded'] = encoder.fit_transform(mod_tweets_df['sourceLabel'].values.reshape(-1, 1))\n",
    "mod_tweets_df['isReplied']   = [0 if type(tweet)==float else 1 for tweet in mod_tweets_df['inReplyToUser']]\n",
    "mod_tweets_df['isMentioned'] = [0 if type(tweet)==float else 1 for tweet in mod_tweets_df['mentionedUsers']]\n",
    "\n",
    "#mod_tweets_df = mod_tweets_df.drop(['sourceLabel','inReplyToUser','mentionedUsers'], axis=1)\n",
    "\n",
    "\n",
    "def extract_dict(line: str, prepare_to_df: False):\n",
    "    \"\"\"Extracts data from a dict represented as string and makes it a dict.\n",
    "\n",
    "    Args:\n",
    "        line (str): row of a Series/DataFrame to be preprocessed.\n",
    "        prepare_to_df (bool): prepares extracted dict to be wrapped into DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dict: extracted dict from string.\n",
    "    \"\"\"    \n",
    "    import re\n",
    "\n",
    "    extracted_content = dict(re.findall(r\"'(\\w+)': '?({.*}|datetime.datetime\\(.*\\)|[\\w\\d/:\\. ]*)'?\", line))\n",
    "    \n",
    "    # Wraps dict values into lists to be easily represented as a DataFrame row.\n",
    "    if prepare_to_df:\n",
    "        for key,value in extracted_content.items():\n",
    "            if value == '':\n",
    "                extracted_content[key] = [None]\n",
    "            else:\n",
    "                extracted_content[key] = value\n",
    "        \n",
    "    return extracted_content\n",
    "\n",
    "\n",
    "new_df = mod_tweets_df.copy()     \n",
    "extracted_df = (pd.DataFrame([*mod_tweets_df['user']\n",
    "                              .apply(lambda x: extract_dict(x, True))])\n",
    "                )\n",
    "\n",
    "new_df = (pd.concat([new_df, extracted_df], axis=1)\n",
    "            .drop(['user','username','id','displayname','verified','created',\n",
    "                    'location','protected','profileImageUrl','profileBannerUrl',\n",
    "                    'rawDescription','renderedDescription','favouritesCount',\n",
    "                    'friendsCount','mediaCount','statusesCount'], axis=1))\n",
    "'''.drop(['user','username','id','displayname','verified','created',\n",
    "                 'location','protected','link','profileImageUrl','profileBannerUrl',\n",
    "                 'label', 'rawDescription','renderedDescription','mediaCount','favouritesCount',\n",
    "                 'descriptionLinks','statusesCount','friendsCount'], axis=1))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns containing numbers to int after extraction.\n",
    "for column in new_df:\n",
    "    if 'Count' in column:\n",
    "        new_df[column] = new_df[column].astype('Int64').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "1) Check whenether @tags are ok for text analysis, \n",
    "   how to treat them.\n",
    "2) Make a column with number of tags.\n",
    "'''\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(new_df.corr(),vmin=-1, vmax=1, annot=True, linecolor='black',linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[['rawContent','isReplied','isMentioned']].query(\"rawContent.str.contains('@')\")\n",
    "\n",
    "new_df['mentionsCount'] = new_df['rawContent'].str.count(r'@[\\w\\d]+')\n",
    "new_df[['rawContent','mentionsCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "new_df['mentions'] = new_df['rawContent'].apply(lambda x : re.findall(r'(@[^\\s]+)', x))\n",
    "\n",
    "count = 0\n",
    "for a,b in new_df[['mentionsCount','mentions']].values:\n",
    "    if a==len(b):\n",
    "        count +=1 \n",
    "print(count==len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.columns[tweets_df.columns.isin(new_df.columns)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary(col_names, plot_size=(16,6)):\n",
    "    fig, ax = plt.subplots(ncols=len(col_names))\n",
    "    fig.set_size_inches(plot_size)   \n",
    "    \n",
    "    for i in range(len(col_names)):\n",
    "        freqs, bins, _ = ax[i].hist(new_df[col_names[i]].values, weights=np.ones(len(new_df))/len(new_df), bins=2, edgecolor='black')\n",
    "        ax[i].set_title(col_names[i])\n",
    "        \n",
    "        bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "        ax[i].set_xticks(bin_centers, [0,1])\n",
    "        ax[i].set_yticks(freqs)\n",
    "        ax[i].set_ylim([0,1])\n",
    "\n",
    "    \n",
    "plot_binary(['isReplied','isMentioned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['charCount'] = new_df['rawContent'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = tweets_df[tweets_df.columns[tweets_df.columns.isin(new_df.columns)==False]]['links'].value_counts().copy()\n",
    "\n",
    "tweets_df[tweets_df['rawContent']=='True']['quotedTweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['quotedTweet'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop('descriptionLinks', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['quotedTweet']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
